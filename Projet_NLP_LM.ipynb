{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build an efficient supervised word translator for English to French and French to English\n",
    "\n",
    "Based on : \"Exploiting Similarities among Languages for Machine Translation\" of Tomas Mikolov, Quoc V. Le & Ilya Sutskever (2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load function for pretrained versions of word embeddings\n",
    "def load_embeddings(emb_path, nmax=50000):\n",
    "    vectors = []\n",
    "    word2id = {}\n",
    "    with io.open(emb_path, 'r', encoding='utf-8', newline='\\n', errors='ignore') as f:\n",
    "        next(f)\n",
    "        for i, line in enumerate(f):\n",
    "            word, vect = line.rstrip().split(' ', 1)\n",
    "            vect = np.fromstring(vect, sep=' ')\n",
    "            assert word not in word2id, 'word found twice'\n",
    "            vectors.append(vect)\n",
    "            word2id[word] = len(word2id)\n",
    "            if len(word2id) == nmax:\n",
    "                break\n",
    "    id2word = {v: k for k, v in word2id.items()}\n",
    "    embeddings = np.vstack(vectors)\n",
    "    return embeddings, id2word, word2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_path = '/Users/louismonier/Downloads/Monolingual/wiki.en.vec' \n",
    "fr_path = '/Users/louismonier/Downloads/Monolingual/wiki.fr.vec'\n",
    "nmax = 50000  # maximum number of word embeddings to load\n",
    "\n",
    "# load monolingual word embeddings \n",
    "src_embeddings, src_id2word, src_word2id = load_embeddings(fr_path, nmax) # source = french \n",
    "tgt_embeddings, tgt_id2word, tgt_word2id = load_embeddings(eng_path, nmax) # target = english"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FRENCH to ENGLISH translation\n",
    "\n",
    "* source language = french\n",
    "* target language = english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read ground-truth bilingual dictionaries function\n",
    "def load_dic(path):\n",
    "    dico_full = {}\n",
    "    vectors_src=[]\n",
    "    vectors_tgt = []\n",
    "    with io.open(path,'r',encoding='utf_8') as f:\n",
    "        for i,line in enumerate(f):\n",
    "            word_src, word_tgt = line.rstrip().split(' ',1)\n",
    "            if word_tgt in tgt_word2id :\n",
    "                dico_full[word_src]=word_tgt\n",
    "    for key in dico_full.keys() :\n",
    "            vectors_src.append(src_embeddings[src_word2id[key]])\n",
    "            vectors_tgt.append(tgt_embeddings[tgt_word2id[dico_full[key]]])\n",
    "    X = np.vstack(vectors_src)\n",
    "    Z = np.vstack (vectors_tgt)\n",
    "    return dico_full,X,Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train & test bilingual dictionaries\n",
    "path_train = r'/Users/louismonier/Downloads/Monolingual/fr-en.0-5000.txt' \n",
    "path_test = r'/Users/louismonier/Downloads/Monolingual/fr-en.5000-6500.txt'\n",
    "dico_train, X_train, Z_train = load_dic(path_train)\n",
    "dico_test, X_test, Z_test = load_dic(path_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a learning a linear mapping from a source (french) to a target (english) embedding space thanks to a translation Matrix W \n",
    "\n",
    "Suppose we are given a set of word pairs and their associated vector representations ${ \\{x_i , z_i\\} }^{n}_{i=1}$ , where $x_i$ ∈ $R^{d1}$ is the distributed representation of word i in the source language, and $z_i$ ∈ $R^{d2}$ is the vector representation of its translation.\n",
    "\n",
    "It is our goal to find a transformation matrix W such that W xi approximates $z_i$ . In practice, W can be learned by the following optimization problem :\n",
    "\n",
    "$$ \\underset{W}{min} C (W) = \\underset{W}{min} \\sum_{i=1}^{n} \\| W x_i - z_i \\|^2 $$ \n",
    "\n",
    "which we solve with gradient descent (GD), stochastic gradient descent (SGD) or mini-batch gradient descent (BGD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4971 training samples\n",
      "1483 test samples\n",
      "d1 dimension : 300\n",
      "d2 dimension : 300\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[0], \"training samples\")\n",
    "print(X_test.shape[0], \"test samples\")\n",
    "\n",
    "print(\"d1 dimension :\", X_train.shape[1])\n",
    "print(\"d2 dimension :\", X_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to minimize\n",
    "def C(W,X,Z):\n",
    "    S = 0\n",
    "    S = sum(np.linalg.norm(np.dot(X, W.T) - Z, axis=1)**2)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient of the function to minimize\n",
    "def GradW(W,X,Z):\n",
    "    G = np.zeros((Z_train.shape[1], X_train.shape[1]))\n",
    "    G = 2*np.dot(X.T, (np.dot(X, W.T) - Z)).T\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GD function\n",
    "def GradientDescent(eta, niter): \n",
    "    W = np.random.rand(300,300) # random initialisation of W\n",
    "    value_C = np.zeros((niter,1))\n",
    "    \n",
    "    for t in range(niter):  \n",
    "        if (t%10==0):\n",
    "            print(t+1, \"steps /\", niter)\n",
    "        value_C[t] = C(W,X_train,Z_train)\n",
    "        W -= eta*GradW(W,X_train,Z_train)\n",
    "    return (W, value_C) #,acc_test,acc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGC or MGD\n",
    "def StochasticGradientDescent(eta, niter, nb):\n",
    "    W = np.random.rand(300,300) # random initialisation of W\n",
    "    grad = 0\n",
    "    value_C = []\n",
    "    \n",
    "    for t in range(niter):\n",
    "        if (t%10 == 0):\n",
    "            print(t+1, \"steps /\", niter)\n",
    "        if nb>1 : # MGD\n",
    "            l = np.random.choice(len(dico_train), nb) # size of batch\n",
    "            print(l)\n",
    "            for p in l : # ok\n",
    "                grad += (2*np.outer((np.dot(W, X_train[p]) - Z_train[p]), X_train[p]))\n",
    "        else : # SGD\n",
    "            l = np.random.randint(low=0,high=len(dico_train)) \n",
    "            grad += (2*np.outer((np.dot(W, X_train[l]) - Z_train[l]), X_train[l]))\n",
    "        \n",
    "        grad = (1/nb)*grad\n",
    "        W -= eta*grad\n",
    "        value_C.append(C(W,X_train,Z_train))\n",
    "        \n",
    "    return (W, value_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "The goal is to find the best W to map the source language to the target one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 steps / 50\n",
      "11 steps / 50\n",
      "21 steps / 50\n",
      "31 steps / 50\n",
      "41 steps / 50\n"
     ]
    }
   ],
   "source": [
    "eta = 5e-5\n",
    "niter = 50\n",
    "\n",
    "W, C = GradientDescent(eta, niter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a39e55dd0>]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Wmin = Z_train.dot(np.linalg.pinv(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 300)\n",
      "(4971, 4971)\n"
     ]
    }
   ],
   "source": [
    "print(W.shape)\n",
    "print(Wmin.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3]\n",
      " [-1  1  4]]\n",
      "[1.41421356 2.23606798 5.        ]\n",
      "[3.74165739 4.24264069]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (100,3) and (6,100) not aligned: 3 (dim 1) != 6 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-170-2b318e38faf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#W_est = np.linalg.pinv(X.T).dot(Z.T).T\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mW_est1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpinv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: shapes (100,3) and (6,100) not aligned: 3 (dim 1) != 6 (dim 0)"
     ]
    }
   ],
   "source": [
    "d2, d1 = 3, 6\n",
    "N = 100  # num samples\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "W = rng.randn(d1, d2)\n",
    "X = rng.randn(N, d1)\n",
    "Z_clean = X.dot(W)\n",
    "print(X.dot(W).shape)\n",
    "\n",
    "Z = Z_clean + rng.randn(*Z_clean.shape) * .001\n",
    "\n",
    "#W_est = np.linalg.pinv(X.T).dot(Z.T).T\n",
    "W_est1 = Z.dot(np.linalg.pinv(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6)\n",
      "(3, 6)\n"
     ]
    }
   ],
   "source": [
    "print(W_est.shape)\n",
    "print(W_est1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the prediction time, for any given new word and its continuous vector representation x, we can map it to the other language space by computing $z = Wx$. Then, we find the word whose representation is closest to z in the target language space, using cosine similarity as the distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(W, new_word):\n",
    "    x = src_embeddings[src_word2id[new_word]] # vector representation of the new word in the source space\n",
    "    z = np.dot(W, x) # vector representation of the translated word in the target space\n",
    "\n",
    "    # representation closest to z in the target language space, using cosine similarity as the distance metric\n",
    "    z_pred = np.argmax(sklearn.metrics.pairwise.cosine_similarity(z.reshape(1,300),tgt_embeddings)) \n",
    "    \n",
    "    return tgt_id2word[z_pred] # return the id of the translated word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a translation French to English dictionary\n",
    "def prediction_dict(dico, W):\n",
    "    dico_pred={}\n",
    "    i=0\n",
    "    for word in dico.keys() :\n",
    "        if (i%10==0):\n",
    "            print(i)\n",
    "        dico_pred[word] = prediction(W, word)\n",
    "        i += 1\n",
    "    return dico_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure of the accuracy of the dictionnarty\n",
    "def accuracy(dico_pred, dico):\n",
    "    c = 0\n",
    "    for key in dico.keys():\n",
    "        if dico[key] == dico_pred[key]:\n",
    "            c += 1\n",
    "    return(c/len(dico)) # nb de mots bien prédits/nb de mots total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.001\n",
    "niter = 30\n",
    "    \n",
    "W, val, aac_test, acc_train = GradientDescent(eta, niter)\n",
    "\n",
    "plt.plot(range(len(val)),val)\n",
    "plt.ylabel('Cost Function')\n",
    "plt.xlabel('Iteration')\n",
    "plt.title(\"Cost function\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "dico_pred = prediction_dict(dico_test)  \n",
    "accuracy_test = accuracy(dico_pred,dico_test)\n",
    "\n",
    "plt.plot(range(0,len(val),10),aac_test)\n",
    "plt.ylabel('Accuracy TestSet')\n",
    "plt.xlabel('Iteration')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adressing the inconsistency\n",
    "\n",
    "Based on \"Normalized Word Embedding and Orthogonal Transform for Bilingual Word Translation\" of Chao Xing, Dong Wang, Chao Liu & Yiye Lin (2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to minimize\n",
    "def C_ortho(W,X,Z):\n",
    "    S=0\n",
    "    for i in range(X.shape[0]):\n",
    "        S+=(W.dot(X[i])).reshape(1,300).dot(Z[i].reshape(300,1))\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient of function to minimize\n",
    "def dC_dW_ortho(W,X,Z):\n",
    "    S=0\n",
    "    for i in range(X.shape[0]):\n",
    "        S+=np.outer(X[i],Z[i])\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orthogonal GD function\n",
    "def orthogonal_GD(alpha,N)\n",
    "    W = np.random.rand(300,300) # random initialisation of W\n",
    "    value_C_ortho = []\n",
    "    \n",
    "    for t in range(N):\n",
    "        W += alpha*dC_dW_ortho(tmp_W,X_train,Z_train)\n",
    "        value_C_ortho.append(C_ortho(W,X_train,Z_train))\n",
    "        \n",
    "    #rajouter contrainte d'orthogonalité sur W \n",
    "    print(value_C_ortho)\n",
    "    print(dC_dW_ortho(W,X_train,Z_train))\n",
    "    print(np.linalg.norm(dC_dW_ortho(W,X_train,Z_train)))\n",
    "    return(W,value_C_ortho)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
